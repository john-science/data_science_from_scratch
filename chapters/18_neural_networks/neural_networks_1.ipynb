{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" This is a brief introductory chapter on Neural Networks.\n",
    "    This is a big topic, and growing every day, so this will\n",
    "    just be the briefest of introductions.\n",
    "    Exciting though.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" The simplest neural network example is a single perceptron.\n",
    "    The idea is that the weighted sum of the inputs has to be\n",
    "    above some threshhold for a neuron to fire.\n",
    "\"\"\"\n",
    "\n",
    "def dot(a, b):\n",
    "    \"\"\" calculate the vector dot product\"\"\"\n",
    "    return sum([a[i] * b[i] for i in range(len(a))])\n",
    "\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x >=0 else 0\n",
    "\n",
    "\n",
    "def perceptron_output(weights, bias, x):\n",
    "    \"\"\" Returns 1 if the the weighted sum of it's inputs is above some threshold,\n",
    "        but returns 0 otherwise.\n",
    "    \"\"\"\n",
    "    calculation = dot(weights, x) + bias\n",
    "    return step_function(calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Now lets's use a perceptron to simulate the fundamentals of computer hardware.\n",
    "    These examples are dead simple, but hilariously recursive, if you think about\n",
    "    the goal.\n",
    "\"\"\"\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "and_gate = partial(perceptron_output, [2, 2], -3)\n",
    "or_gate = partial(perceptron_output, [2, 2], -1)\n",
    "not_gate = partial(perceptron_output, [-2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and gate\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "or gate\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "\n",
      "not gate\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('and gate')\n",
    "print(and_gate([7, 2]))\n",
    "print(and_gate([1, 1]))\n",
    "print(and_gate([0, 1]))\n",
    "print(and_gate([1, 0]))\n",
    "print(and_gate([0, 0]))\n",
    "\n",
    "print('\\nor gate')\n",
    "print(or_gate([7, 2]))\n",
    "print(or_gate([1, 1]))\n",
    "print(or_gate([0, 1]))\n",
    "print(or_gate([1, 0]))\n",
    "print(or_gate([0, 0]))\n",
    "\n",
    "print('\\nnot gate')\n",
    "print(not_gate([7]))\n",
    "print(not_gate([1]))\n",
    "print(not_gate([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Okay, enough with the single perceptron.\n",
    "    Let's build a simple feed-forward network.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(dot(weights, inputs))\n",
    "\n",
    "\n",
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\" takes in a neural network (list of lists of lists of weights)\n",
    "        and returns the output from forward-propogating the input.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    \n",
    "    # process one layer at a time\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]\n",
    "        output = [neuron_output(neuron, input_with_bias) for neuron in layer]\n",
    "        outputs.append(output)\n",
    "        \n",
    "        # then the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [9.38314668300676e-14]\n",
      "0 1 [0.9999999999999059]\n",
      "1 0 [0.9999999999999059]\n",
      "1 1 [9.383146683006828e-14]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Feed-Forward Example\"\"\"\n",
    "xor_network = [[[20, 20, -30], [20, 20, -10]], [[-60, 60, -30]]]\n",
    "\n",
    "for x in [0, 1]:\n",
    "    for y in [0, 1]:\n",
    "        print(x, y, feed_forward(xor_network, [x, y])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" All right, now let's build a simple backpropogation algorithm.\n",
    "    We will use it to defeat... the world's simplest captcha.\n",
    "\"\"\"\n",
    "\n",
    "def backpropogate(network, input_vector, targets):\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "    \n",
    "    # the output * (1 - output) is from the derivative of the sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target)\n",
    "                     for output, target in zip(outputs, targets)]\n",
    "    \n",
    "    # adjust weights for the output layer, one neuron at a time\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        # focus on the ith output layer neuron\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            # adjust the jth weight based on both\n",
    "            # this neuron's delta & its jth input\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "            \n",
    "    # back-propogate errors in hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                     dot(output_deltas, [n[i] for n in output_layer])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "    \n",
    "    # adjust weights for hidden layer, one neuron at a time\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_digits = [\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             1...1\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"..1..\n",
    "             ..1..\n",
    "             ..1..\n",
    "             ..1..\n",
    "             ..1..\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             11111\n",
    "             1....\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"1...1\n",
    "             1...1\n",
    "             11111\n",
    "             ....1\n",
    "             ....1\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1....\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1....\n",
    "             11111\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             ....1\n",
    "             ....1\n",
    "             ....1\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             11111\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\"]\n",
    "    \n",
    "    \n",
    "def make_digit(raw_digit):\n",
    "    \"\"\"parse the raw text above into our digit images\"\"\"\n",
    "    return [1 if c == '1' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "    \n",
    "inputs = list(map(make_digit, raw_digits))\n",
    "\n",
    "targets = [[1 if i == j else 0 for i in range(10)]\n",
    "           for j in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Okay, it's time to train the neural network.\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "input_size = 25\n",
    "num_hidden = 5\n",
    "output_size = 10\n",
    "\n",
    "hidden_layer = [[random.random() for _ in range(input_size + 1)]\n",
    "                for _ in range(num_hidden)]\n",
    "\n",
    "output_layer= [[random.random() for _ in range(num_hidden + 1)]\n",
    "               for _ in range(output_size)]\n",
    "\n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "for _ in range(10000):\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropogate(network, input_vector, target_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.95', '0.00', '0.00', '0.02', '0.00', '0.00', '0.00', '0.00', '0.03', '0.02']\n",
      "['0.00', '0.96', '0.01', '0.01', '0.02', '0.00', '0.00', '0.02', '0.00', '0.00']\n",
      "['0.00', '0.02', '0.99', '0.01', '0.00', '0.00', '0.02', '0.00', '0.02', '0.00']\n",
      "['0.02', '0.02', '0.01', '0.98', '0.00', '0.00', '0.00', '0.00', '0.01', '0.00']\n",
      "['0.00', '0.02', '0.00', '0.00', '0.98', '0.02', '0.00', '0.00', '0.00', '0.00']\n",
      "['0.00', '0.00', '0.00', '0.00', '0.02', '0.96', '0.03', '0.00', '0.00', '0.02']\n",
      "['0.00', '0.00', '0.00', '0.00', '0.00', '0.02', '0.96', '0.00', '0.03', '0.00']\n",
      "['0.00', '0.02', '0.00', '0.00', '0.00', '0.00', '0.00', '0.97', '0.00', '0.02']\n",
      "['0.03', '0.00', '0.00', '0.00', '0.00', '0.00', '0.03', '0.00', '0.95', '0.00']\n",
      "['0.03', '0.00', '0.00', '0.00', '0.00', '0.02', '0.00', '0.02', '0.00', '0.97']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Let's test the network we trained. \"\"\"\n",
    "\n",
    "def predict(input):\n",
    "    return feed_forward(network, input)[-1]\n",
    "\n",
    "for n in range(10):\n",
    "    print(['%.2f' % p for p in predict(inputs[n])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.996', '0.000', '0.000', '0.497', '0.000', '0.000', '0.000', '0.000', '0.963', '0.000']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" What if we try testing a new input? \"\"\"\n",
    "\n",
    "new_three = [0,1,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,0,1,1,0,\n",
    "             0,0,0,1,1,\n",
    "             0,1,1,1,0]\n",
    "\n",
    "print(['%.3f' % p for p in predict(new_three)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.002', '0.000', '0.000', '0.000', '0.000', '0.019', '0.000', '0.018', '0.000', '0.851']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_nine = [1,1,1,1,1,\n",
    "            1,0,0,0,1,\n",
    "            1,1,1,1,1,\n",
    "            0,0,0,0,1,\n",
    "            0,0,0,0,1]\n",
    "\n",
    "print(['%.3f' % p for p in predict(new_nine)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA/Pxx/XixLkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd207d520f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "weights = network[0][4]\n",
    "abs_weights = list(map(abs, weights))\n",
    "\n",
    "grid = [abs_weights[row:(row + 5)] for row in range(0, 25, 5)]\n",
    "ax = plt.gca()\n",
    "ax.imshow(grid, cmap=matplotlib.cm.binary, interpolation='none')\n",
    "\n",
    "def patch(x, y, color):\n",
    "    return matplotlib.patches.Rectangle((x - 0.5, y - 0.5), 1, 1, color=color)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if weights[5 * i + j] < 0:\n",
    "            ax.add_patch(patch(j, i, \"white\"))\n",
    "            ax.add_patch(patch(j, i, \"black\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
